{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL\n",
    "#1. Twitter API - https://developer.twitter.com/apps\n",
    "#2. Access token: 860552192968712192-GUj7zPoOhLNa2SiAbZBjhP3zgR3jI2t\n",
    "#3. Access token secret: PY3Osvw6roExUh22MCs0K8fWHom3834WIctJSET8M7PGC\n",
    "#4. API key: oOOLEPPMTs7vcmqOeXKUEHJG0\n",
    "#5. API secret key: a8OT9BwDfQtwYxCY6zDHydQb21mNXmGUJPCDplQcKJQFpgfYSg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Search tweets\n",
    "# dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}\n",
    "# for status in python_tweets.search(**query)['statuses']:\n",
    "#     dict_['user'].append(status['user']['screen_name'])\n",
    "#     dict_['date'].append(status['created_at'])\n",
    "#     dict_['text'].append(status['text'])\n",
    "#     dict_['favorite_count'].append(status['favorite_count'])\n",
    "\n",
    "# # Structure data in a pandas DataFrame for easier manipulation\n",
    "# df = pd.DataFrame(dict_)\n",
    "# df.sort_values(by='favorite_count', inplace=True, ascending=False)\n",
    "# df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "\n",
    "TWITTER_APP_KEY = 'oOOLEPPMTs7vcmqOeXKUEHJG0'  #supply the appropriate value\n",
    "TWITTER_APP_KEY_SECRET = 'a8OT9BwDfQtwYxCY6zDHydQb21mNXmGUJPCDplQcKJQFpgfYSg' \n",
    "TWITTER_ACCESS_TOKEN = '860552192968712192-GUj7zPoOhLNa2SiAbZBjhP3zgR3jI2t'\n",
    "TWITTER_ACCESS_TOKEN_SECRET = 'PY3Osvw6roExUh22MCs0K8fWHom3834WIctJSET8M7PGC'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Twython(app_key=TWITTER_APP_KEY, \n",
    "            app_secret=TWITTER_APP_KEY_SECRET, \n",
    "            oauth_token=TWITTER_ACCESS_TOKEN, \n",
    "            oauth_token_secret=TWITTER_ACCESS_TOKEN_SECRET)\n",
    "\n",
    "search = t.search(q='#DepressionIsReal',count=1)\n",
    "# search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = search['statuses']\n",
    "# tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224358358599241728 \n",
      " RT @blackwell_dgf: 'Lost in Life' by Dave Blackwell\n",
      "\n",
      "https://t.co/1XxyXrPIiw\n",
      "\n",
      "#Kindle #KindleUnlimited #writing #WritingCommunity #bibliophâ€¦\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "  print(tweet['id_str'], '\\n', tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create own keyword dataset from scratch - https://towardsdatascience.com/extracting-keywords-from-short-text-fce39157166b\n",
    "#keyword extraction existing module - RAKE short for Rapid Automatic Keyword Extraction algorithm\n",
    "#processing for custom dataset - https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "from rake_nltk import Rake\n",
    "\n",
    "r = Rake() # Uses stopwords for english from NLTK, and all puntuation characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do - clean text data\n",
    "import re\n",
    "text = \"I like kitty and puppy while developing on systems\"\n",
    "# text = tweets[0]['text']\n",
    "text = re.sub(r'http\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.extract_keywords_from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like kitty', 'systems', 'puppy', 'developing']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get_ranked_phrases() # To get keyword phrases ranked highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to build hierarchical classifier from scratch - https://github.com/richliao/textClassifier\n",
    "#to find the main idea/root word - https://www.kdnuggets.com/2018/08/understanding-language-syntax-and-structure-practitioners-guide-nlp-3.html\n",
    "#textClassification using Word2Vec - https://github.com/richliao/textClassifier\n",
    "#text classification - https://github.com/brightmart/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to try - https://github.com/sloria/www/blob/master/content/2013-09-30-tutorial-wordnet-textblob.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch\n",
    "#remove stopword \n",
    "#steming\n",
    "#find sentiment - remove sentiment words\n",
    "#parent category - https://stackoverflow.com/questions/54625493/how-to-group-wikipedia-categories-in-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
